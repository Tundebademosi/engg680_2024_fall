{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**AIR QUALITY MONITORING**"],"metadata":{"id":"TethPr02TomB"}},{"cell_type":"markdown","source":["**Background**\n","\n","The objective of this project is to monitor and analyze the air quality trend in our environment specifically the Southeast Calgary area. Air quality readings were sourced from Calgary Region Airshed Zone (CRAZ) for the last 10 years (from 2014 - 2024) from the Calgary SE & Inglewood Craz's monitoring station."],"metadata":{"id":"oUfbAv3xT33_"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"SY8b-qTdTVpP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733423438928,"user_tz":420,"elapsed":24195,"user":{"displayName":"Kushal","userId":"16535747439567900262"}},"outputId":"d46581b0-ac7f-4b13-fb71-02e78ba081ad"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/engg680_2024_fall/Group_18_Project"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-7huaPzJFzVQ","executionInfo":{"status":"ok","timestamp":1733423487042,"user_tz":420,"elapsed":566,"user":{"displayName":"Kushal","userId":"16535747439567900262"}},"outputId":"03c10d5d-1a99-4393-a349-00a7e6250199"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/engg680_2024_fall/Group_18_Project\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import glob\n","import os\n","\n","# Defining  the correct file path (relative to the python ipnyb file location\n","file_path = \"/content/drive/MyDrive/engg680_2024_fall/Group_18_Project/craz air data\"  # Using the relative path to the folder to extract all csv files\n","file_names = glob.glob(os.path.join(file_path, \"*.csv\"))  # Get all CSV files in the folder\n","\n","if not file_names:\n","    print(\"No files found in the specified directory. Check the folder and try again.\")\n","else:\n","    all_data = []\n","    for file in file_names:\n","        try:\n","            # Read each file, combining the 2nd and 3rd rows as column headers. This would be done to help track Calgry NG and Calgry SE\n","            df = pd.read_csv(file, header=[1, 2])  # Use multi-level header (rows 2 and 3)\n","\n","            # Extract the year from the file name (e.g., \"2014 hourly.csv\")\n","            year = os.path.basename(file).split()[0]  # Extract the year from the file name\n","            df[\"Year\"] = int(year)  # Add the year as a column\n","\n","            # Flatten the multi-level column headers into single strings\n","            df.columns = [\"_\".join(filter(None, col)).strip() for col in df.columns]\n","\n","            # Append the processed DataFrame to the list\n","            all_data.append(df)\n","        except Exception as e:\n","            print(f\"Error processing file {file}: {e}\")\n","            continue\n","\n","    # Combine all files into a single DataFrame\n","    if all_data:\n","        merged_data = pd.concat(all_data, ignore_index=True)\n","\n","        # Display the DataFrame in the notebook\n","        print(\"Data merged successfully. Displaying first 5 rows:\")\n","        display(merged_data.head())  # Use display() to show the DataFrame in the notebook\n","\n","        # Saving to a CSV file just to be sure of all the rows and columns not missing out.\n","        merged_data.to_csv(\"Merged_Air_Quality_Data.csv\", index=False)\n","        print(\"Merged data saved as 'Merged_Air_Quality_Data.csv'.\")\n","    else:\n","        print(\"No data could be processed.\")"],"metadata":{"id":"8mK7nh2lFn_9"},"execution_count":null,"outputs":[]}]}